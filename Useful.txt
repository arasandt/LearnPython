https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ide-c9.html?msclkid=c029124bd10a11eca96de14cbe276ad3
echo "alias py=python3.9" >> ~/.bashrc 
echo "alias python3=python3.9" >> ~/.bashrc 
echo "alias pip3=pip3.9" >> ~/.bashrc 
echo "alias csyn='cdk synthesize --quiet'" >> ~/.bashrc 
echo "alias cboot='cdk bootstrap'" >> ~/.bashrc 
echo "alias cdiff='cdk diff'" >> ~/.bashrc 
echo "alias cdep='cdk deploy --all --require-approval never'" >> ~/.bashrc 
echo "alias cdeph='cdk deploy --hotswap --all'" >> ~/.bashrc 
echo "alias gitm='git add -u && git commit -m minorchange && git push'" >> ~/.bashrc 
echo "alias gitf='git add -u && git commit -m codeformatter && git push'" >> ~/.bashrc 
echo 'gitpush() { git add -u && git commit -m "$1" && git push;}' >> ~/.bashrc
source ~/.bashrc
export PS1='\e[36m[\@]\033[00m\] \033[01;32m\]$(_cloud9_prompt_user)\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]$(__git_ps1 " (%s)" 2>/dev/null)\n$ '
git config --global user.name "Arasan Dayalan"
git config --global user.email thiru.arasan.dayalan@accenture.com
git config --global alias.st status
git config --global alias.lga "log --topo-order --graph --date=local --pretty=format:'%C(green)%h%C(reset) %><(55,trunc)%s%C(red)%d%C(reset) %C(blue)[%an]%C(reset) %C(yellow)%ad%C(reset)'"

clear;
;
# Get remediation action status
aws configservice describe-remediation-execution-status --config-rule-name CDKCIPComplianceStack-Cloud9SecurityGroupRule14CC9-1CDQQ7K4L00IW --query 'RemediationExecutionStatuses[].[State,InvocationTime,LastUpdatedTime]'

# to find python files and format it using black
find /home/ec2-user/environment/cip-uw-emailreceipt/ -name *.py | grep -v ".venv" | grep -v "cdk.out" | grep -v "test" | grep -v ".~" | grep -v "_archive" | grep -v "__init__" | grep -v  "psycopg2" | grep -v  "idna" | grep -v  "urllib3" | grep -v  "requests" | grep -v  "certifi" | grep -v  "charset_normalizer" | grep -v  "pyparsing" | grep -v  "typing_extensions" | grep -v  "packaging"  | grep -v  "zipp" | grep -v  "importlib_metadata" | grep -v  "redis" | grep -v  "wrapt"
find /home/ec2-user/environment/cip-uw-doc-classification/ -name *.py | grep -v ".venv" | grep -v "cdk.out" | grep -v "test" | grep -v ".~" | grep -v "_archive" | grep -v "__init__" | grep -v  "psycopg2"

#  check when aws config was run to pull data. Usually runs every 6 hours.
aws configservice describe-configuration-recorder-status

# to install packages in the folder when using lambda for linux
pip install --platform manylinux2014_x86_64 --implementation cp --python 3.9 --only-binary=:all: --upgrade -r ./python/requirements.txt -t ./python

# Comprehend commands
aws comprehend describe-document-classifier --document-classifier-arn arn:aws:comprehend:us-east-2:241231414837:document-classifier/documenttype1/version/1
aws comprehend list-document-classifiers

# access shared mailbox in graph explorer
https://graph.microsoft.com/v1.0/users/test.cip.uw.docs@accenture.com/messages


aws lambda get-function-configuration --function-name CDKCIPUWEmailReceiptStack-cipuwmailboxmonitor47EBF-W0eJV7uvvb5x --query "Environment" > environment.json
envs=$(jq --arg var1 "$token" '.Variables.TOKEN = $var1' environment.json)
echo $envs > environment.json
aws lambda update-function-configuration --function-name CDKCIPUWEmailReceiptStack-cipuwmailboxmonitor47EBF-W0eJV7uvvb5x --environment file://environment.json --query "Environment"
aws lambda get-function-configuration --function-name CDKCIPUWEmailReceiptStack-cipuwmailboxsweeper557DF-5fckAv3iegGa --query "Environment" > environment.json
envs=$(jq --arg var1 "$token" '.Variables.TOKEN = $var1' environment.json)
echo $envs > environment.json
aws lambda update-function-configuration --function-name CDKCIPUWEmailReceiptStack-cipuwmailboxsweeper557DF-5fckAv3iegGa  --environment file://environment.json --query "Environment"

#test docker function locally
sam local invoke -t <path to the CF template> -e <events json file>

#If GIT is not working on AWS Cloud9
git clone https://Username:Password@git-codecommit.us-east-1.amazonaws.com/v1/repos/cip-uw-base/

#install postgresql
amazon-linux-extras install postgresql11 -y
yum install -y postgresql-server postgresql-devel
/usr/bin/postgresql-setup --initdb
systemctl enable postgresql
systemctl start postgresql
systemctl status postgresql
https://dailyscrawl.com/how-to-install-postgresql-on-amazon-linux-2/


# connect to postgres database
psql --host=cip-uw-smart-labeler-serverless.cluster-c5td3go0h4db.us-east-2.rds.amazonaws.com --port=5432 --username=tfndrycfxnmtzxec --dbname=cipuwdev
pg_dump -Cs -h cip-uw-smart-labeler-serverless.cluster-c5td3go0h4db.us-east-2.rds.amazonaws.com -p 5432 -U tfndrycfxnmtzxec -n public cipuwdev -f /tmp/schema_public.sql
aws s3 cp /tmp/schema_public.sql s3://cip-uw-email-inbound


# with schema name
pg_dump -Cs -h cip-uw-smart-labeler-serverless.cluster-c5td3go0h4db.us-east-2.rds.amazonaws.com -p 5432 -U tfndrycfxnmtzxec -n public cipuwdev -n publicaig -f schema_public.sql

psql --host=cip-uw-smart-labeler-serverless.cluster-cigmgiakybio.us-east-2.rds.amazonaws.com --port=5432 --username=nsavinrefxxrytmk --dbname=cipuwdemo < cipuwdemo.sql
### not working -- pg_restore -h cip-uw-smart-labeler-serverless.cluster-cigmgiakybio.us-east-2.rds.amazonaws.com -p 5432 -U nsavinrefxxrytmk -n public -d cipuwdemo -f cipuwdemo.sql



psql --host=uw-doc-insight-aig-poc.cluster-ccuyuwana2w7.us-east-1.rds.amazonaws.com --port=5432 --username=postgres_docins --dbname=uw_doc_insight_aigpoc_baseline
Docins$aig12$
1. pg_dump -Cs -h uw-doc-insight-aig-poc.cluster-ccuyuwana2w7.us-east-1.rds.amazonaws.com -p 5432 -U postgres_docins -n public uw_doc_insight_aigpoc -f uw_doc_insight_aigpoc.sql
2. CREATE DATABASE uw_doc_insight_aigpoc WITH TEMPLATE = template0 ENCODING = 'UTF8' LC_COLLATE = 'en_US.UTF-8' LC_CTYPE = 'en_US.UTF-8';
3. ALTER DATABASE uw_doc_insight_aigpoc OWNER TO postgres;
3a. Change sql file to rename postgres_docins to postgres and database to uw_doc_insight_aigpoc_baseline
4. psql --host=claims-dev-241231414837-u-smartlabelerserverless08-zm3houw1qi4a.cluster-coe0l1dyobfr.us-west-2.rds.amazonaws.com --port=5432 --username=postgres --dbname=uw_doc_insight_aigpoc_baseline < uw_doc_insight_aigpoc.sql
4a. Delete unnecessary tables
5.\COPY public.dim_image_quality_quartiles FROM 'dim_image_quality_quartiles.txt' DELIMITER ',' CSV HEADER;
6.\COPY public.dim_document_field_setup_table FROM 'dim_document_field_setup_table.txt' DELIMITER ',' CSV HEADER;
7.\COPY public.document_type FROM 'document_type.txt' DELIMITER ',' CSV HEADER;
8.\COPY public.dim_dropdown_setup FROM 'dim_dropdown_setup.txt' DELIMITER ',' CSV HEADER;
9.\COPY public.dim_field_category_mapping_setup FROM 'dim_field_category_mapping_setup.txt' DELIMITER ',' CSV HEADER;
create the actual database from baseline
10. pg_restore -h claims-dev-241231414837-u-smartlabelerserverless08-zm3houw1qi4a.cluster-coe0l1dyobfr.us-west-2.rds.amazonaws.com -p 5432 -U postgres -d uw_doc_insight_aigpoc -v "uw_doc_insight_aigpoc_baseline.backup"
10. pg_restore -h claimsdemo-demo-571021761-smartlabelerserverless08-bltdoti7rwce.cluster-ckyfbyrisq8n.us-west-2.rds.amazonaws.com -p 5432 -U postgres -d uw_doc_insight_aigpoc -v "uw_doc_insight_aigpoc_baseline.backup"

psql --host=uw-doc-insight-aig-poc.cluster-ccuyuwana2w7.us-east-1.rds.amazonaws.com --port=5432 --username=postgres_docins --dbname=uw_doc_insight_aigpoc -c 'COPY dim_field_category_mapping_setup    TO stdout' | psql --host=uw-doc-insight-aig-poc.cluster-ccuyuwana2w7.us-east-1.rds.amazonaws.com --port=5432 --username=postgres_docins --dbname=uw_doc_insight_aigpoc_baseline -c 'COPY dim_field_category_mapping_setup   FROM stdin'

# Termination sessions in DB before deleting the database
SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity 
WHERE pg_stat_activity.datname = 'uw_doc_insight_aigpoc_baseline' AND pid <> pg_backend_pid();


# identify yourself in AWS
aws sts get-caller-identify

# Pylint command
pylint --disable C0301,C0330,R0913,R0912,R0915,W0703,R0914 *.py


# CURL POST command
curl -X POST -H "Content-Type: application/json" -d '{"title":"hello"}' https://649kntcql2.execute-api.us-east-2.amazonaws.com/development/submit
curl -X POST -H "Content-Type: application/json" -d '{"title":"hello"}' https://api.uw-dev.cognitiveinsurance.accenture.com/meawebhook/submit
curl -X POST -H "Content-Type: application/json" -H "x-api-key: ABC"  -d '{"title":"hello"}' https://api.uw-dev.cognitiveinsurance.accenture.com/meawebhook/submit
curl -X POST -H "{'Content-Type': 'text/plain'}" -d '{"AuthParameters": {"USERNAME": "", "PASSWORD": ""}, "ClientId": ""}' https://apiengine-aigpreprd.meaplatform.com/rest/api/v1/token

# in case git clone fails and does not show prompt, try this
git config --global credential.helper store

# bulk replace
find . -type f -exec sed -i 's/cip-appetite-dl-landing-ue1-dev/{{appetitelandingbucket}}/g' {} +

#Clear Lambda Storage CF ERROR Code storage limit exceeded
git clone https://github.com/epsagon/clear-lambda-storage
cd clear-lambda-storage/
pip install -r requirements.txt
python clear_lambda_storage.py

# check for CORS 
curl -v -X OPTIONS https://uw-api.cognitiveinsurance.accenture.com/winpropensity/PropensityScoring?application_id=APP202210130003

# remove all local changes in git
git clean -df && git checkout -- .

# Empty folder and subfolder of all files
find ./* -type f -exec rm "{}" \;

# remove c9_invoke files.
find $pwd -name *.~c9_invoke*.py -type f -exec rm "{}" \;  

# docker search based on container name and get logs
docker logs -f $(docker ps | grep gpu | cut -c 1-4) --tail 100	

# docker how long the container has ben running
docker container inspect --format '{{.State.StartedAt }}'

#Deepracer stop training
cd deepracer-for-cloud/ && source bin/activate.sh && dr-stop-training
    "lr": 0.00000001, 0.0003
{
    "batch_size": 64,
    "beta_entropy": 0.01,
    "discount_factor": 0.95,
    "e_greedy_value": 1.0,
    "epsilon_steps": 10000,
    "exploration_type": "categorical",
    "loss_type": "mean squared error",
    "lr": 0.0003,
    "num_episodes_between_training": 18,
    "num_epochs": 4,
    "stack_size": 1,
    "term_cond_avg_score": 100000.0,
    "term_cond_max_episodes": 1800,
    "sac_alpha": 0.2
}

aws s3 cp s3://dp123testlocal/rl-dp-rf10cosmic s3://elasticbeanstalk-us-east-1-152706161531/rl-dp-rf10cosmic --recursive --acl bucket-owner-full-control


# App Integration with Cognito
curl --location --request POST 'https://meaconnection.auth.us-east-1.amazoncognito.com/oauth2/token' --header 'Content-Type: application/x-www-form-urlencoded' --header 'Authorization: Basic ' --data-urlencode 'grant_type=client_credentials' --data-urlencode 'client_id=' --data-urlencode 'scope=read/read'
curl --location --request POST 'https://meaintegration.auth.us-east-2.amazoncognito.com/oauth2/token' --header 'Content-Type: application/x-www-form-urlencoded' --header 'Authorization: Basic ' --data-urlencode 'grant_type=client_credentials' --data-urlencode 'client_id=' --data-urlencode 'scope=basic/basic'
curl --request POST 'https://f9hcln6wrd.execute-api.us-east-2.amazonaws.com/prod/awesomeapi' --header 'Authorization: XX' -d '{"templateName": "IM01-Default Template"}' 

#install python3.9
sudo yum -y install wget yum-utils make gcc openssl-devel bzip2-devel libffi-devel zlib-devel
wget https://www.python.org/ftp/python/3.9.6/Python-3.9.6.tgz 
tar xzf Python-3.9.6.tgz 
cd Python-3.9.6
sudo ./configure --with-system-ffi --with-computed-gotos --enable-loadable-sqlite-extensions
sudo make -j ${nproc} 
sudo make altinstall 
rm -f /bin/python3; ln -s /usr/local/bin/python3.9 /bin/python3
rm -f /usr/bin/python3; ln -s /usr/local/bin/python3.9 /usr/bin/python3
rm -f /usr/bin/pip3; ln -s /usr/local/bin/pip3.9 /usr/bin/pip3


# Install Docker Compose
sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose version
sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /bin/docker-compose
sudo chmod +x /bin/docker-compose


# update cdk cli
npm install -g aws-cdk --force 

# add git tags and checkout based on tags
git tag -a Release1.0 76bd76d -m "Released to AIG Dev on 03/14 before Phase 2 changes"
git push --tags origin master
git checkout tags/Release1.0


# get public ip of the instance
curl -s http://169.254.169.254/latest/meta-data/public-ipv4

# Add / remove policy from role using cli
aws iam detach-role-policy --role-name viper-cip-uw-admin-role --policy-arn arn:aws:iam:::policy/DenyCodeCommitDeletes
aws iam attach-role-policy --role-name viper-cip-uw-admin-role --policy-arn arn:aws:iam:::policy/DenyCodeCommitDeletes
aws iam list-attached-role-policies --role-name viper-cip-uw-admin-role

#proxy aws cli
setx HTTP_PROXY http://XX.XX.com:9480
setx HTTPS_PROXY http://XX.XX..com:9480
setx AWS_CA_BUNDLE "C:\Users\T22S1ED\Downloads\AWS Zscaler Root CA.pem"
aws s3 ls --ca-bundle "C:\Users\T22S1ED\Downloads\AWS Zscaler Root CA.pem"
aws configure sso
aws sso login --sso-session Arasan
aws sts assume-role --role-arn XX --role-session-name "default" --profile xxprofile 
https://docs.aws.amazon.com/cli/latest/userguide/sso-using-profile.html
https://docs.aws.amazon.com/cli/latest/userguide/sso-configure-profile-token.html


# SSM session using AWS CLI
aws --region us-east-1 ssm start-session --target i-09e7a7d343fed94d6
source ~/.bashrc;echo $(curl -s http://169.254.169.254/latest/meta-data/local-ipv4) $(curl -s http://169.254.169.254/latest/meta-data/instance-id); cd ~;pwd;ls -l
echo $(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)
echo $(curl -s http://169.254.169.254/latest/meta-data/instance-id)

http://169.254.169.254/latest/meta-data/iam/security-credentials/

# Vi copy correctly
:set paste

# mobaxterm
history
!30:p

# EKS and Kubectl cluster commands
cd /tmp
sudo yum remove awscli
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
aws --version
curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.26.8/2023-09-14/bin/linux/amd64/kubectl
chmod +x ./kubectl
mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH
open ~/.bashrc and add export PATH=$HOME/bin:$PATH
aws eks update-kubeconfig --name eksclustername --region us-east-1 
==> install HELM
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 > get_helm.sh
chmod 700 get_helm.sh
./get_helm.sh

# Get into EKS POD
kubectl exec -it clientshare-deployment-989998bfc-5w6qp -n tc -- bash

# Git commands
git config --global --unset http.proxy
git config --global --unset https.proxy
git config --global --get http.proxy
git config --global --unset http.sslVerify
git config --global credential.helper cache
git config --global credential.helper store
ssh-keygen -t ed25519 -C "thiru_arasandayalan@newyorklife.com"
ssh-add ~/.ssh/id_ed25519
clip < ~/.ssh/id_ed25519.pub
git_branch() {
  git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \(.*\)/(\1)/'
}
export PS1='\n[\t] \[\e[93m\]\u\[\e[0m\]@\[\e[92m\]\h\[\e[0m\] \[\e[94m\]\w\[\e[91;1m\] $(git_branch)\n\[\e[0m\]\$ '
alias k="kubectl"

# docker commands
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 905523019479.dkr.ecr.us-east-1.amazonaws.com
docker run -it account#.dkr.ecr.us-east-1.amazonaws.com/dev-default-eks-alpine-cmf-base-image:1.0 /bin/sh

# EC2 java and maven install
sudo amazon-linux-extras enable corretto8
sudo yum install java-1.8.0-amazon-corretto-devel
sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo
sudo sed -i s/\$releasever/6/g /etc/yum.repos.d/epel-apache-maven.repo
sudo yum install -y apache-maven
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-amazon-corretto.x86_64

# Java Application creation through  docker
FROM 905523019479.dkr.ecr.us-east-1.amazonaws.com/ekscorporatevs-dev-default-eks-alpine-cmf-base-image:1.0
USER root 
RUN wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.80/bin/apache-tomcat-9.0.80.tar.gz -P /tmp
RUN mkdir /opt/tomcat
RUN tar -xvzf /tmp/apache-tomcat-9.0.80.tar.gz -C /opt/tomcat --strip-components=1
RUN rm -f /tmp/apache-tomcat-9.0.80.tar.gz
RUN chmod -R 755 /opt/tomcat	
RUN apk add openjdk8 --repository=http://dl-cdn.alpinelinux.org/alpine/edge/community
COPY target/suggestion.war /opt/tomcat/webapps
RUN echo 'JAVA_OPTS="$JAVA_OPTS -Dspring.profiles.active=int"' > /opt/tomcat/bin/setenv.sh
RUN chmod -R 755 /opt/tomcat/bin/setenv.sh
EXPOSE 8080
ENTRYPOINT ["/opt/tomcat/bin/catalina.sh", "run"]

# run the java container
docker build -t app .
docker run -it -p 80:8080 app
docker exec -it e9b /bin/sh
cat /opt/tomcat/logs/app.log
curl http://localhost/app/appurl

# Bin SH commands
get permission on the file --> stat -c '%a' shutdown.bat

# install jfrog cli
cd /tmp
echo "[jfrog-cli]" > jfrog-cli.repo &&
echo "name=jfrog-cli" >> jfrog-cli.repo &&
echo "baseurl=https://releases.jfrog.io/artifactory/jfrog-rpms" >> jfrog-cli.repo &&
echo "enabled=1" >> jfrog-cli.repo &&
sudo rpm --import https://releases.jfrog.io/artifactory/jfrog-gpg-public/jfrog_public_gpg.key &&
sudo mv jfrog-cli.repo /etc/yum.repos.d/ &&
sudo yum install -y jfrog-cli-v2-jf &&
jf intro
jf c add
jf rt u app.war path/to/artifactory
jf rt s --spec=aql.json

# Server Set-up
sudo yum remove python3 -y
sudo amazon-linux-extras enable python3.8
sudo yum clean metadata
sudo yum install python3.8 -y
sudo rm -f /usr/bin/python3; sudo ln -s /usr/bin/python3.8 /usr/bin/python3
sudo rm -f /usr/bin/pip3; sudo ln -s /usr/bin/pip3.8 /usr/bin/pip3
python3 --version
==> set up EKS after this

# install backstage
git clone --branch v1.18.4 https://github.com/backstage/backstage.git nyl-backstage
cd /tmp
curl https://raw.githubusercontent.com/creationix/nvm/master/install.sh | bash
source ~/.bashrc
nvm ls-remote
nvm install 18.18.0 
nvm use 18.18.0
npm install --global yarn
sudo yum -y groupinstall "Development Tools"
cd ~
npx @backstage/create-app@latest
cd backstage && yarn install or yarn install --frozen-lockfile
yarn tsc
yarn build:backend --config ../../app-config.yaml
sudo chmod 666 /var/run/docker.sock
sudo usermod -a -G docker ec2-user
sudo systemctl enable docker
sudo systemctl start docker
sudo systemctl status docker
updated docker file to use nodejs 18
docker image build . -f packages/backend/Dockerfile --tag backstage or yarn build-imag
docker run -it -p 7007:7007 backstage
aws ecr create-repository --repository-name backstage --profile eng-ekscorporatevs-dev
docker tag backstage account#.dkr.ecr.us-east-1.amazonaws.com/backstage
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin account#.dkr.ecr.us-east-1.amazonaws.com
docker push account#.dkr.ecr.us-east-1.amazonaws.com/backstage
helm upgrade --install backstage chart/backstage/ --dry-run --debug
--Run locally ---
yarn dev
yum install -y nginx
sudo vi /etc/nginx/nginx.conf
add the below

        location / {
        proxy_pass http://localhost:3000/;
        }

sudo systemctl restart nginx
sudo dnf -y install postgresql15 postgresql15-server
sudo postgresql-setup initdb
sudo systemctl start postgresql
sudo systemctl enable postgresql
sudo systemctl status postgresql

# Add remove port in Security group
aws ec2 authorize-security-group-ingress --group-id sg-0a8795711cb03e0cf --cidr 10.0.0.0/0 --protocol tcp --port 7007
aws ec2 revoke-security-group-ingress --group-id sg-0a8795711cb03e0cf --cidr 10.0.0.0/0 --protocol tcp --port 7007

# Start / Stop Ec2 Instance
aws ec2 start-instances --instance-ids i-047af98a7ee3eba3d i-075708304839fc563 i-001feeb289b97dc2b --profile eng-profile-dev
aws ec2 stop-instances --instance-ids i-047af98a7ee3eba3d i-075708304839fc563 i-001feeb289b97dc2b --profile eng-profile-dev
aws ec2 start-instances --instance-ids i-0bff8c8e112a301de i-04b8c5d41fb171a7d --profile eng-profile-dev 
aws ec2 stop-instances --instance-ids i-0bff8c8e112a301de i-04b8c5d41fb171a7d --profile eng-profile-dev 

aws ec2 describe-instances --query 'Reservations[].Instances[].[ [Tags[?Key==`Name`].Value][0][0],PrivateIpAddress,State.Name]' --output table

# Submit Cloudformation stack and delete it
aws cloudformation deploy --stack-name DevelopmentBase --template-file "./cdk.out/DevelopmentBase.template.json" --no-execute-changeset --profile eng-profile-dev 
aws cloudformation delete-stack --stack-name DevelopmentBase --profile eng-profile-dev

# Connect to EC2 instance using SSH
cd .ssh
ssh-keygen -t rsa -b 4096 -f id_rsa_backstage
ssh-copy-id -f -i id_rsa_backstage.pub ec2-user@10.195.126.108
ssh ec2-user@10.195.126.108

# install git in Amazon Linux 2023
sudo dnf install git -y

# install docker in Amazon Linux 2023
sudo dnf update
sudo dnf install -y docker
docker --version

# install nginx in Amazon Linux 2023
sudo dnf install -y nginx

# kubectl k8s set namespace 
kubectl config set-context --current --namespace=backstage

# clean up pods
#
# Clean up dying pods
#
pods=$( kubectl get pods | tail -n +1 | awk -F " " '{print $1}' )
for pod in $pods;
do
    kubectl delete pod $pod --force
done

# tfdocs creation
docker run --rm --volume "$(pwd):/terraform-docs" -u $(id -u) quay.io/terraform-docs/terraform-docs:0.16.0 markdown /terraform-docs > docs/index.md


